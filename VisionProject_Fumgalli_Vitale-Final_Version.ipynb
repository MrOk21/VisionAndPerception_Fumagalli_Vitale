{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFpbMRfNb-CF"
      },
      "source": [
        "# Import Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJPaSG7XagRu"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import skimage\n",
        "from skimage.transform import resize\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, Dense, Flatten, BatchNormalization, Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "print(\"Packages imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuOJg8BXsLse"
      },
      "source": [
        "# Drive Mounting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a7EQUPffuqI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPiRcIxzsP0B"
      },
      "source": [
        "# Import Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMm5iyBigWlf"
      },
      "outputs": [],
      "source": [
        "training_dir = '/content/drive/MyDrive/VisionProject/Dataset/ASL_Alphabet/asl_alphabet_train/asl_alphabet_train'\n",
        "\n",
        "def import_train_data(folder):\n",
        "  x = []\n",
        "  y = []\n",
        "  cont = 0\n",
        "  \n",
        "  mask = {\n",
        "      \"A\": 0,\n",
        "      \"B\": 1,\n",
        "      \"C\": 2,\n",
        "      \"D\": 3,\n",
        "      \"E\": 4,\n",
        "      \"F\": 5,\n",
        "      \"G\": 6,\n",
        "      \"H\": 7,\n",
        "      \"I\": 8,\n",
        "      \"J\": 9,\n",
        "      \"K\": 10,\n",
        "      \"L\": 11,\n",
        "      \"M\": 12,\n",
        "      \"N\": 13,\n",
        "      \"O\": 14,\n",
        "      \"P\": 15,\n",
        "      \"Q\": 16,\n",
        "      \"R\": 17,\n",
        "      \"S\": 18,\n",
        "      \"T\": 19,\n",
        "      \"U\": 20,\n",
        "      \"V\": 21,\n",
        "      \"W\": 22,\n",
        "      \"X\": 23,\n",
        "      \"Y\": 24,\n",
        "      \"Z\": 25,\n",
        "      \"del\": 26,\n",
        "      \"nothing\": 27,\n",
        "      \"space\": 28,\n",
        "  }\n",
        "  for folderName in os.listdir(folder):\n",
        "    cont_per_class = 0\n",
        "    if not folderName.startswith('.'):\n",
        "      label = mask[folderName]\n",
        "      for image_filename in os.listdir(folder + '/' + folderName):\n",
        "        img_file = cv2.imread(folder + '/' + folderName + '/' + image_filename)\n",
        "        if img_file is not None:\n",
        "          img_file = skimage.transform.resize(img_file, (64, 64, 3))\n",
        "          img_arr = np.asarray(img_file)\n",
        "              \n",
        "          x.append(img_arr)\n",
        "          y.append(label)\n",
        "          cont += 1\n",
        "          # if cont > 2000:\n",
        "          #   return np.array(x), np.array(y)\n",
        "          cont_per_class += 1\n",
        "        if cont_per_class == 1700:\n",
        "            print(\"Class \" + folderName + \" done\")\n",
        "            break\n",
        "\n",
        "  return np.array(x), np.array(y)\n",
        "\n",
        "x_train, y_train = import_train_data(training_dir)\n",
        "\n",
        "print(\"Training images successfully imported\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7jh0uuQsT5R"
      },
      "source": [
        "# Import Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rf12rmg_0As-"
      },
      "outputs": [],
      "source": [
        "test_dir = '/content/drive/MyDrive/VisionProject/Dataset/ASL_Alphabet/asl_alphabet_test/asl_alphabet_test'\n",
        "\n",
        "def import_test_data(folder):\n",
        "  x = []\n",
        "  y = []\n",
        "  cont = 0 \n",
        "  mask = {\n",
        "      \"A\": 0,\n",
        "      \"B\": 1,\n",
        "      \"C\": 2,\n",
        "      \"D\": 3,\n",
        "      \"E\": 4,\n",
        "      \"F\": 5,\n",
        "      \"G\": 6,\n",
        "      \"H\": 7,\n",
        "      \"I\": 8,\n",
        "      \"J\": 9,\n",
        "      \"K\": 10,\n",
        "      \"L\": 11,\n",
        "      \"M\": 12,\n",
        "      \"N\": 13,\n",
        "      \"O\": 14,\n",
        "      \"P\": 15,\n",
        "      \"Q\": 16,\n",
        "      \"R\": 17,\n",
        "      \"S\": 18,\n",
        "      \"T\": 19,\n",
        "      \"U\": 20,\n",
        "      \"V\": 21,\n",
        "      \"W\": 22,\n",
        "      \"X\": 23,\n",
        "      \"Y\": 24,\n",
        "      \"Z\": 25,\n",
        "      \"del\": 26,\n",
        "      \"nothing\": 27,\n",
        "      \"space\": 28,\n",
        "  }\n",
        "  for folderName in os.listdir(folder):\n",
        "    cont_per_class = 0\n",
        "    if not folderName.startswith('.'):\n",
        "      label = mask[folderName]\n",
        "      for image_filename in os.listdir(folder + '/' + folderName):\n",
        "        img_file = cv2.imread(folder + '/' + folderName + '/' + image_filename)\n",
        "        if img_file is not None:\n",
        "          img_file = skimage.transform.resize(img_file, (64, 64, 3))\n",
        "          img_arr = np.asarray(img_file)\n",
        "              \n",
        "          x.append(img_arr)\n",
        "          y.append(label)\n",
        "          cont += 1\n",
        "          # if cont > 1000:\n",
        "          #   return np.array(x), np.array(y)\n",
        "          cont_per_class += 1\n",
        "        if cont_per_class == 550:\n",
        "          print(\"Class \" + folderName + \" done\")\n",
        "          break\n",
        "  return np.array(x), np.array(y)\n",
        "\n",
        "x_test, y_test = import_test_data(test_dir)\n",
        "\n",
        "print(\"Test images successfully imported\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97fAC4EJsYql"
      },
      "source": [
        "# Shape Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3athcQ6i5D67"
      },
      "outputs": [],
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3s6XFtLpQKKc"
      },
      "source": [
        "#One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooA7ReK4Plbm"
      },
      "outputs": [],
      "source": [
        "y_ohe_train = to_categorical(y_train, 29)\n",
        "print(y_ohe_train.shape)\n",
        "print(y_ohe_train[0])\n",
        "y_ohe_test = to_categorical(y_test, 29)\n",
        "print(y_ohe_test.shape)\n",
        "print(y_ohe_test[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esbib1l-sdUK"
      },
      "source": [
        "# Training Data Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IJtYk0dz2sT3"
      },
      "outputs": [],
      "source": [
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_ohe_train, test_size=0.3,random_state=42,shuffle = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHnAVhmjouvX"
      },
      "source": [
        "# Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTEExNbgR4Ig"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (5,5), input_shape = (64, 64, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "# model.add(Dropout(0.7))\n",
        "\n",
        "\n",
        "model.add(Conv2D(64, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Conv2D(128, (3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization(momentum=0.99))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "\n",
        "model.add(Dense(29, activation = 'softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(optimizer = opt, \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBkKMk16osZq"
      },
      "source": [
        "# Model 1 Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZw0shX0oneo"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (5, 5), input_shape=(64, 64, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.add(Dense(29, activation='softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "model.compile(optimizer = opt, \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov8nDFRUu3PN"
      },
      "source": [
        "# Model 2 Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuogutM0u70P"
      },
      "outputs": [],
      "source": [
        "\n",
        "  model = Sequential()\n",
        "    \n",
        "  model.add(Conv2D(64, (3, 3),padding='same',input_shape=(64, 64, 3)))\n",
        "  model.add(Conv2D(64, (3, 3),padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3),padding='same',input_shape=(64, 64, 3)))\n",
        "  model.add(Conv2D(64, (3, 3),padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3),padding='same',input_shape=(64, 64, 3)))\n",
        "  model.add(Conv2D(64, (3, 3),padding='same'))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(128))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  model.add(Dense(29))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
        "  model.compile(optimizer = opt, \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "  print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc-0HU0Vq_Ty"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iu7dLvPeTZkk"
      },
      "outputs": [],
      "source": [
        "early_stops = EarlyStopping(monitor = 'val_loss', patience = 5)\n",
        "checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/VisionProject/Weights/weights_best.hdf5', verbose=1, save_best_only=True) # Model\n",
        "#checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/VisionProject/Weights/weights_best1.hdf5', verbose=1, save_best_only=True) # Model 1\n",
        "#checkpointer = ModelCheckpoint(filepath='/content/drive/MyDrive/VisionProject/Weights/weights_best2.hdf5', verbose=1, save_best_only=True) # Model 2\n",
        "history = model.fit(x_train, y_train,\n",
        "          epochs = 10,\n",
        "          batch_size = 64,\n",
        "          verbose = 2,\n",
        "          validation_data = (x_valid, y_valid),\n",
        "          callbacks = [early_stops, checkpointer])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kSj-KyQS5qcv"
      },
      "outputs": [],
      "source": [
        "def plot_history(history,name=\"Model\"):\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(name + ' accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('/content/drive/MyDrive/VisionProject/Results/Accuracy/accuracy1700-550(Final 3 - 14 - check[20 epoche][tutte]BatchNormalization=0.99&[2 e 3]drop=0.7&opt).png') # Model\n",
        "    #plt.savefig('/content/drive/MyDrive/VisionProject/Results/Accuracy/accuracy1700-550(Final Model 1 - 8 - check[20 epoche].png') # Model 1\n",
        "    #plt.savefig('/content/drive/MyDrive/VisionProject/Results/Accuracy/accuracy1700-550(Final Model 2 - 2 - check[20 epoche].png') # Model 2\n",
        "    plt.show()\n",
        "    \n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(name + ' loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.savefig('/content/drive/MyDrive/VisionProject/Results/Loss/loss1700-550(Final 3 - 14 - check[10 epoche][tutte]BatchNormalization=0.99&[2 e 3]drop=0.7&opt).png') # Model\n",
        "    #plt.savefig('/content/drive/MyDrive/VisionProject/Results/Loss/Loss1700-550(Final Model 1 - 8 - check[10 epoche].png') # Model 1\n",
        "    #plt.savefig('/content/drive/MyDrive/VisionProject/Results/Loss/Loss1700-550(Final Model 2 - 2 - check[20 epoche].png') # Model 2\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKLLxuUR5jOk"
      },
      "outputs": [],
      "source": [
        "loss, acc = model.evaluate(x_valid, y_valid, verbose = 0)\n",
        "print(\"Validation Loss: %.2f\" % (loss))\n",
        "print(\"Validation Accuracy: %.3f\" % (acc))\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3d2TVa2SVQCd"
      },
      "outputs": [],
      "source": [
        "results = model.predict(x_test)\n",
        "results = np.argmax(results, axis = 1)\n",
        "\n",
        "conv = {\n",
        "    0: \"A\", \n",
        "    1: \"B\",\n",
        "    2: \"C\",\n",
        "    3: \"D\",\n",
        "    4: \"E\",\n",
        "    5: \"F\",\n",
        "    6: \"G\",\n",
        "    7: \"H\",\n",
        "    8: \"I\",\n",
        "    9: \"J\",\n",
        "    10: \"K\",\n",
        "    11: \"L\",\n",
        "    12: \"M\",\n",
        "    13: \"N\",\n",
        "    14: \"O\",\n",
        "    15: \"P\",\n",
        "    16: \"Q\",\n",
        "    17: \"R\",\n",
        "    18: \"S\",\n",
        "    19: \"T\",\n",
        "    20: \"U\",\n",
        "    21: \"V\",\n",
        "    22: \"W\",\n",
        "    23: \"X\",\n",
        "    24: \"Y\",\n",
        "    25: \"Z\",\n",
        "    26: \"del\",\n",
        "    27: \"nothing\",\n",
        "    28: \"space\",\n",
        "  }\n",
        "y_pred = [conv[i] for i in results]\n",
        "print(\"Prediction done:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_TcnK5bVcqU"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22OreogjVwTD"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (12,12))\n",
        "sns.heatmap(confusion_matrix(y_test, results))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KQIANN1A5nV"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, results)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, results, cmap=\"Blues\")\n",
        "# print(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zesIFmHOqBtE"
      },
      "source": [
        "# Model Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAR2tqdgqDYv"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/VisionProject/Models/ASL.h5')\n",
        "print(\"Model saved successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE56Ogkjp6Ej"
      },
      "source": [
        "# Model 1 Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ2bVvFmWBYu"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/VisionProject/Models/ASL1.h5')\n",
        "print(\"Model saved successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKk-Dz0OwW7d"
      },
      "source": [
        "# Model 2 Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAavBvduwYz-"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/VisionProject/Models/ASL2.h5')\n",
        "print(\"Model saved successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfKk5dRopn9O"
      },
      "source": [
        "# Model Load\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4RVLaMhrbp0"
      },
      "outputs": [],
      "source": [
        "model = load_model('/content/drive/MyDrive/VisionProject/Models/ASL.h5')\n",
        "model.load_weights('/content/drive/MyDrive/VisionProject/Weights/weights_best.hdf5')\n",
        "print(\"Model restore with best weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw6aZ3mWpy0Y"
      },
      "source": [
        "# Model 1 Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7D_FWHhdpxto"
      },
      "outputs": [],
      "source": [
        "model = load_model('/content/drive/MyDrive/VisionProject/Models/ASL1.h5')\n",
        "model.load_weights('/content/drive/MyDrive/VisionProject/Weights/weights_best1.hdf5')\n",
        "print(\"Model restore with best weights\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWcdo548wb5j"
      },
      "source": [
        "# Model 2 Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd4MwEtqweUd"
      },
      "outputs": [],
      "source": [
        "model = load_model('/content/drive/MyDrive/VisionProject/Models/ASL2.h5')\n",
        "model.load_weights('/content/drive/MyDrive/VisionProject/Weights/weights_best2.hdf5')\n",
        "print(\"Model restore with best weights\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}